{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d052e9ea-f4f6-4a24-81d2-64c7a891a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "7858\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "Ошибка: Нет интернет-соединения.\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "  Team_Radiant Team_Dire        Hero_Rad_1   Hero_Rad_2        Hero_Rad_3  \\\n",
      "0      Radiant      Dire  Legion Commander        Pudge              Zeus   \n",
      "1      Radiant      Dire              Lina    Underlord   Vengeful Spirit   \n",
      "2      Radiant      Dire            Clinkz         Ursa  Legion Commander   \n",
      "3      Radiant      Dire         Alchemist         Lion           Slardar   \n",
      "4      Radiant      Dire         Dark Seer  Earthshaker          Snapfire   \n",
      "\n",
      "   Hero_Rad_4        Hero_Rad_5       Hero_Dire_1    Hero_Dire_2  \\\n",
      "0  Grimstroke              Sven            Enigma   Nyx Assassin   \n",
      "1   Morphling             Pudge      Chaos Knight      Sand King   \n",
      "2      Enigma             Pudge  Phantom Assassin           Lich   \n",
      "3    Hoodwink  Templar Assassin             Slark  Skywrath Mage   \n",
      "4  Windranger  Treant Protector  Templar Assassin        Techies   \n",
      "\n",
      "      Hero_Dire_3      Hero_Dire_4   Hero_Dire_5                   DateTime  \\\n",
      "0       Pangolier             Lina          Ursa  2024-07-23T22:23:34+00:00   \n",
      "1  Crystal Maiden     Earth Spirit          Tiny  2024-07-23T06:22:01+00:00   \n",
      "2    Nyx Assassin  Vengeful Spirit  Shadow Fiend  2024-07-22T22:50:38+00:00   \n",
      "3            Tusk      Dark Willow     Dark Seer  2024-07-22T22:19:10+00:00   \n",
      "4     Broodmother           Rubick     Sand King  2024-07-22T21:21:10+00:00   \n",
      "\n",
      "    Result  \n",
      "0  Radiant  \n",
      "1     Dire  \n",
      "2     Dire  \n",
      "3  Radiant  \n",
      "4  Radiant   (7147, 14)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "#from requests_proxy import ProxyManager\n",
    "import socks\n",
    "import socket\n",
    "\n",
    "socks.set_default_proxy(socks.SOCKS5, \"localhost\", 9150)\n",
    "socket.socket = socks.socksocket\n",
    "\n",
    "# Функция для загрузки страницы с использованием случайного User-Agent\n",
    "def load_page(url):\n",
    "    try:\n",
    "        ua = UserAgent()\n",
    "        headers = {'User-Agent': ua.random}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        time.sleep(random.uniform(0.5,1.5))  # Добавляем небольшую задержку между запросами, чтобы избежать блокировки\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if soup is not None:\n",
    "            return soup\n",
    "        else:\n",
    "            time.sleep(60)\n",
    "    except requests.ConnectionError:\n",
    "        print(\"Ошибка: Нет интернет-соединения.\")\n",
    "        time.sleep(600)\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Ошибка при загрузке страницы {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_match_info(match_url):\n",
    "    soup = load_page(match_url)\n",
    "    if soup is not None:\n",
    "    # Извлечение информации о матче\n",
    "        if soup.find('div', class_='header-content-secondary'):\n",
    "            datetime = soup.find('div', class_='header-content-secondary').find('time').get('datetime')\n",
    "        else:\n",
    "            time.sleep(10)\n",
    "            return None\n",
    "        try:\n",
    "            team_1 = soup.find('div', class_='team-results').find('section', class_='radiant').find('span', class_='team-text team-text-full').text\n",
    "        except:\n",
    "            team_1 = 'Radiant'\n",
    "        try:\n",
    "            team_2 = soup.find('div', class_='team-results').find('section', class_='dire').find('span', class_='team-text team-text-full').text\n",
    "        except:\n",
    "            team_2 = 'Dire'\n",
    "        try:\n",
    "            try:\n",
    "                result = soup.find('div', class_='match-result team radiant').find('span', class_=\"team-text team-text-full\").text.strip()\n",
    "            except:\n",
    "                result = soup.find('div', class_='match-result team dire').find('span', class_=\"team-text team-text-full\").text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                result = soup.find('div', class_='match-result team radiant').text.strip().replace(' Victory', '')\n",
    "            except:\n",
    "                result = soup.find('div', class_='match-result team dire').text.strip().replace(' Victory', '')\n",
    "    # Извлечение информации о героях \n",
    "        heroes = []\n",
    "        hero_elements = soup.find_all('div', class_='image-container image-container-hero image-container-icon')\n",
    "        for hero_element in hero_elements:\n",
    "            hero_name = hero_element.find('a').find('img').get('title').strip()\n",
    "            heroes.append(hero_name)\n",
    "        try:\n",
    "            match_info = {\n",
    "            'DateTime': datetime,\n",
    "            'Team_Radiant': team_1,\n",
    "            'Team_Dire': team_2,\n",
    "            'Result': result,\n",
    "            'DateTime': datetime,\n",
    "            'Hero_Rad_1': heroes[0],\n",
    "            'Hero_Rad_2': heroes[1],\n",
    "            'Hero_Rad_3': heroes[2],\n",
    "            'Hero_Rad_4': heroes[3],\n",
    "            'Hero_Rad_5': heroes[4],\n",
    "            'Hero_Dire_1': heroes[5],\n",
    "            'Hero_Dire_2': heroes[6],\n",
    "            'Hero_Dire_3': heroes[7],\n",
    "            'Hero_Dire_4': heroes[8],\n",
    "            'Hero_Dire_5': heroes[9]\n",
    "        }\n",
    "            return match_info\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "start_urls = [\n",
    "             ]\n",
    "page_urls = start_urls\n",
    "for start_url in start_urls:\n",
    "    soup = load_page(start_url)\n",
    "    if soup is not None:\n",
    "        page = soup.find('span', class_='next')\n",
    "        try:\n",
    "            if 'https://www.dotabuff.com' + page.find('a')['href'] in page_urls:\n",
    "                continue\n",
    "            else:\n",
    "                page_urls.append('https://www.dotabuff.com' + page.find('a')['href'])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print(len(page_urls))\n",
    "\n",
    "match_urls = []\n",
    "for page in page_urls:\n",
    "    soup = load_page(page)\n",
    "    # Извлечение ссылок на матчи\n",
    "    matchestd = soup.find_all('td', class_='cell-large')\n",
    "    for matches in matchestd:\n",
    "        matchesa = matches.find_all('a')\n",
    "        for match in matchesa:\n",
    "            if 'https://www.dotabuff.com' + match['href'] in match_urls:\n",
    "                continue\n",
    "            else:\n",
    "                match_urls.append('https://www.dotabuff.com' + match['href'])\n",
    "                \n",
    "print(len(match_urls))\n",
    "\n",
    "data = []\n",
    "for match_url in match_urls:\n",
    "    match_info = get_match_info(match_url)\n",
    "    if match_info != None:\n",
    "        data.append(match_info)\n",
    "        if len(data) % 100 == 0:\n",
    "            print(len(data))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Team_Radiant', 'Team_Dire', 'Hero_Rad_1', 'Hero_Rad_2', 'Hero_Rad_3', 'Hero_Rad_4', 'Hero_Rad_5', \\\n",
    "                                 'Hero_Dire_1', 'Hero_Dire_2', 'Hero_Dire_3', 'Hero_Dire_4', 'Hero_Dire_5', 'DateTime', 'Result'])\n",
    "\n",
    "desktop_path = str(Path.home() / \"Desktop\")\n",
    "# Сохранение датасета в CSV\n",
    "df.to_csv(os.path.join(desktop_path, \"dota2dataset17.csv\"), index=False)\n",
    "\n",
    "\n",
    "print(df.head(), df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffa75d4-148e-4224-9494-71b0af47c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current IP Address: 192.42.116.182\n"
     ]
    }
   ],
   "source": [
    "def checkIP():\n",
    "    ip = requests.get('http://checkip.dyndns.org').content\n",
    "    soup = BeautifulSoup(ip, 'html.parser')\n",
    "    print(soup.find('body').text)\n",
    "\n",
    "checkIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6326588b-50f2-4270-a1a5-969f65b863bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current IP Address: 192.42.116.182\n"
     ]
    }
   ],
   "source": [
    "import socks\n",
    "import socket\n",
    "socks.set_default_proxy(socks.SOCKS5, \"localhost\", 9150)\n",
    "socket.socket = socks.socksocket\n",
    "checkIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944e5321-7b00-40a8-afdf-ad49e27b92d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current IP Address: 192.42.116.182\n",
      "Current IP Address: 162.247.74.206\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     checkIP()\n\u001b[1;32m----> 3\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    checkIP()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2eb0e2-2527-4b02-9b5c-73cee0c2957a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
